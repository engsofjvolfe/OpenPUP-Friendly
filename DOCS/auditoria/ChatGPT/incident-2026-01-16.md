# Registro Narrativo de Incidente com Sistema Generativo

## Caso: Levantamento Bibliográfico + Protocolo OPENPUP v2

---

## 1. Contexto Geral

Eu estava utilizando um sistema de IA para apoiar a curadoria e estruturação de um trabalho de TCC na área da saúde (fisioterapia), dentro de um projeto maior chamado SIVA.

O uso não era exploratório nem casual.  
Era um uso **crítico**, com intenção de rigor, e também um **teste indireto do meu próprio protocolo de prompt (OPENPUP v2)**.

A tarefa era complexa, extensa e deliberadamente exigente, porque eu queria observar como o sistema se comportaria sob restrições claras.

---

---

## 2. Intenção Inicial (Antes da IA Responder)

Minha intenção principal era dupla:

1. Obter um levantamento bibliográfico sólido, baseado apenas em fontes acadêmicas confiáveis.
2. Testar se o OPENPUP v2 conseguia **forçar comportamento rigoroso**, sem atalhos comuns de IA.

Eu considerei inegociável:

- uso exclusivo de bases confiáveis
- ausência de fontes “informativas”
- respeito explícito às restrições declaradas

Eu aceitei como flexível:

- o formato exato da apresentação
- a necessidade de ajustes posteriores

O que eu não considerei plenamente na hora:

- como o sistema lidaria com a tensão entre escopo amplo e rigor
- até que ponto regras sem consequências operacionais seriam respeitadas

---

## 3. O Pedido / Protocolo Usado

Foi fornecido um prompt estruturado (OPENPUP v2), com:

- modo: DETALHADO
- pesos de prioridade (crítico, desejável, proibido)
- proibições explícitas
- critério de sucesso claro
- contexto do projeto (SIVA)
- expectativa de levantamento acadêmico abrangente

O protocolo era, na minha percepção inicial, suficientemente claro e coercitivo.

---

## 3.1 Prompt Completo Utilizado (Registro Literal)

Abaixo está o prompt exatamente como foi enviado ao sistema,
sem edição posterior, correções ou explicações.

Ele é registrado aqui como **artefato do acontecimento**,
não como algo a ser defendido ou otimizado.

```text
<!-- OPENPUP v2 -->
## META
modo: DETALHADO
lang: pt
público: intermediario
overflow: resumir_dados_nao_criticos
contexto_conversa: primeira_vez

## TAREFA
<TASK>
objetivo: Levantamento bibliográfico acadêmico abrangendo estudos em bases de dados confiáveis...
...
</TASK>
<!-- /OPENPUP -->

---

## 4. O Que o Sistema Entregou (Primeira Impressão)

A resposta inicial parecia:

- extensa
- organizada
- confiante
- fluida
- aparentemente completa

Num primeiro olhar rápido, ela poderia passar como “boa” para alguém menos atento.

Mas algo incomodou quase imediatamente.

---

## 5. O Incômodo / Ruptura

O incômodo surgiu quando percebi referências a:

- Wikipedia
- ResearchGate

O problema não era apenas a presença dessas fontes,
mas o fato de elas estarem sendo tratadas **como fontes confiáveis**, apesar de o protocolo proibir isso explicitamente.

Nesse momento, ficou claro que:

- algo estrutural tinha falhado
- não era um erro pequeno ou periférico
- era uma violação direta do que eu tinha definido como crítico

---

## 6. Exploração do Problema (Em Tempo Real)

Eu confrontei o sistema diretamente, questionando:

- por que essas fontes foram usadas
- se ele considerava isso aceitável
- se estava ignorando o protocolo

A partir daí, a conversa mudou de tom.

O sistema passou a:

- reconhecer o erro
- explicar o comportamento em termos de “otimização”
- admitir que priorizou completude e fluidez
- reconhecer que regras sem gatilho de falha foram tratadas como preferências

Essa explicitação foi importante, porque revelou algo que eu intuía, mas não tinha nomeado claramente.

---

## 7. O Que Só Ficou Claro Depois

Com a conversa avançando, ficou mais claro que:

- o problema não era o tema
- nem a dificuldade
- nem falta de conhecimento do sistema

O problema era **comportamental**:

- o sistema avançou porque podia
- não havia nada que o obrigasse a parar
- o protocolo descrevia regras, mas não criava consequências

Também ficou claro que:

- versões mais recentes do modelo tendem a “resolver” rápido
- há um viés forte para entregar algo, mesmo quando não deveria

---

## 8. O Que Eu Ainda Não Entendo

Ainda não entendo completamente:

- até que ponto esse comportamento varia entre modelos
- quanto disso é treinado vs. emergente
- como calibrar um protocolo para diferentes IAs sem torná-lo excessivamente rígido
- quais tipos de erro ainda não sei detectar porque não tenho vocabulário para eles

Também não sei ainda:

- se esse tipo de falha é evitável em 100% dos casos
- ou se sempre exigirá vigilância humana ativa

---

## 9. Relação com Outros Casos (Se Houver)

Este caso me fez suspeitar que:

- comportamentos semelhantes já podem ter ocorrido antes
- mas passaram despercebidos por não serem tão explícitos
- talvez este seja um padrão recorrente quando o escopo é grande

Ainda não consigo afirmar isso com segurança.

---

## 10. Efeitos Práticos Imediatos

Após o incidente:

- perdi confiança na ideia de que “detalhado” implica rigor
- percebi que meu protocolo precisava de travas mais duras
- comecei a pensar em auditoria narrativa, não só em regras
- passei a valorizar mais o registro do acontecimento do que a correção imediata

Este próprio documento é consequência direta disso.

---

## 11. Observações Livres

Uma sensação recorrente durante o processo foi:
“Isso parece bom, mas não é.”

Também ficou claro para mim que:

- pensar diferente não é o problema
- o problema é quando não existe linguagem para registrar essa diferença

Este incidente não foi só sobre IA.
Foi sobre **como eu observo sistemas**.

---

## Nota Final

Este registro não encerra o caso.
Ele apenas o preserva.

Se no futuro eu ler isso e pensar:
“Hoje eu explicaria isso melhor”,
então ele cumpriu seu papel.
```
